{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7533d19",
   "metadata": {},
   "source": [
    "# 导入库并且导入机器学习的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd892a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas._libs.testing as _testing\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Dense, Layer, Add\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dense, Activation, GRU, LSTM, Dropout, Input, Embedding, RepeatVector, concatenate, Convolution2D, Conv2D, BatchNormalization, LayerNormalization, MultiHeadAttention, Conv1D, GlobalMaxPooling1D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model, CustomObjectScope\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  \n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "file_path = filedialog.askopenfilename()\n",
    "\n",
    "folder_path = os.path.dirname(file_path)\n",
    "\n",
    "file_name = os.path.basename(file_path)\n",
    "\n",
    "df = pd.read_excel(file_path, sheet_name=\"MachineLearningData\")\n",
    "\n",
    "\n",
    "features = df.iloc[:, :-1].values   \n",
    "target = df.iloc[:, -1].values  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()  #\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2514d271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "class TrainingTimeCallback(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = time.time()\n",
    "    def on_train_end(self, logs=None):\n",
    "        total_time = time.time() - self.start_time\n",
    "        print(f\"Total training time: {total_time} seconds\")\n",
    "\n",
    "\n",
    "class ResidualBlock(Layer):\n",
    "\n",
    "    def __init__(self, num_filters, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(**kwargs)\n",
    "        self.num_filters = num_filters\n",
    "        self.conv1 = Conv2D(num_filters, (3, 3), padding='same')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.relu1 = Activation('relu')\n",
    "        self.conv2 = Conv2D(num_filters, (3, 3), padding='same')\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.relu2 = Activation('relu')\n",
    "        self.add = Add()\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.add([x, input_tensor])\n",
    "        return self.relu2(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ResidualBlock, self).get_config()\n",
    "        config['num_filters'] = self.num_filters\n",
    "        return config \n",
    "    \n",
    "\n",
    "custom_objects = {\n",
    "    'ResidualBlock': ResidualBlock\n",
    "}\n",
    "\n",
    "class TransformerEncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "\n",
    "        self.multi_head_attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.layer_norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(dff, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(d_model)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.layer_norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attention_output = self.multi_head_attention(inputs, inputs)\n",
    "        attention_output = self.dropout1(attention_output, training=training)\n",
    "        attention_output = self.layer_norm1(inputs + attention_output)\n",
    "\n",
    "        dense_output = self.dense1(attention_output)\n",
    "        dense_output = self.dense2(dense_output)\n",
    "        dense_output = self.dropout2(dense_output, training=training)\n",
    "        output = self.layer_norm2(attention_output + dense_output)\n",
    "        return output\n",
    "    \n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, num_heads, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        batch_size, seq_len, embedding_dim = input_shape\n",
    "   \n",
    "        self.head_dim = embedding_dim // self.num_heads\n",
    "\n",
    "        tf.debugging.assert_equal(embedding_dim % self.num_heads, 0,\n",
    "                                  message='Embedding dimension must be divisible by the number of heads.')\n",
    "\n",
    "        self.query_dense = Dense(embedding_dim)\n",
    "        self.key_dense = Dense(embedding_dim)\n",
    "        self.value_dense = Dense(embedding_dim)\n",
    "\n",
    "        self.multihead_attention = MultiHeadAttention(self.num_heads, self.head_dim)\n",
    "        self.dense = Dense(embedding_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        queries = self.query_dense(inputs)\n",
    "        keys = self.key_dense(inputs)\n",
    "        values = self.value_dense(inputs)\n",
    "\n",
    "        attention_output = self.multihead_attention(queries, keys, values)\n",
    "\n",
    "        output = self.dense(attention_output)\n",
    "        return output\n",
    "    \n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[1]\n",
    "        d_model = tf.shape(inputs)[2]\n",
    "        position = tf.math.cumsum(tf.ones_like(inputs[:, :, 0]), axis=1, exclusive=True)\n",
    "        position_enc = tf.cast(position, tf.float32)[:, tf.newaxis, :]\n",
    "        div_term = tf.exp(tf.range(0, tf.cast(d_model, tf.float32), 2) * -(tf.math.log(10000.0) / tf.cast(d_model, tf.float32)))\n",
    "        div_term = div_term[tf.newaxis, tf.newaxis, :]\n",
    "        position_enc = position_enc * div_term\n",
    "        position_enc = tf.concat([tf.math.sin(position_enc), tf.math.cos(position_enc)], axis=-1)\n",
    "        position_enc = tf.expand_dims(position_enc, axis=2)\n",
    "        position_enc = tf.reshape(position_enc, tf.shape(inputs))\n",
    "        return inputs + position_enc\n",
    "    \n",
    "def transformer_block(inputs, num_heads, dff, dropout_rate):\n",
    "\n",
    "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(inputs, inputs)\n",
    "    attention = layers.Dropout(dropout_rate)(attention)\n",
    "    attention = layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    outputs = layers.Dense(units=dff, activation=\"relu\")(attention)\n",
    "    outputs = layers.Dense(units=d_model)(outputs)\n",
    "    outputs = layers.Dropout(dropout_rate)(outputs)\n",
    "    outputs = layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88767d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_select = 'CNN'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4e7281",
   "metadata": {},
   "source": [
    "# All models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b15a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "elif model_select == 'DNN':\n",
    "    ## DNN\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    history = model.fit(X_train, y_train, epochs=1000, batch_size=256, validation_data=(X_test, y_test), callbacks=[TrainingTimeCallback()])\n",
    "    model.save(f'{model_select}-model.h5')\n",
    "\n",
    "elif model_select == 'LSTM':\n",
    "    # LSTM\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    history = model.fit(X_train, y_train, epochs=1000, batch_size=256, validation_data=(X_test, y_test), callbacks=[TrainingTimeCallback()])\n",
    "    model.save(f'{model_select}-model.h5')\n",
    "    \n",
    "elif model_select == 'GRU':\n",
    "    # （GRU）\n",
    "    model = Sequential()\n",
    "    model.add(GRU(128, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    history = model.fit(X_train, y_train, epochs=1000, batch_size=256, validation_data=(X_test, y_test), callbacks=[TrainingTimeCallback()])\n",
    "    model.save(f'{model_select}-model.h5')\n",
    "    \n",
    "elif model_select == 'CNN':\n",
    "    ##（CNN）\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(256, 3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(MaxPooling1D(1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    history = model.fit(X_train, y_train, epochs=1000, batch_size=256, validation_data=(X_test, y_test), callbacks=[TrainingTimeCallback()])\n",
    "    model.save(f'{model_select}-model.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d3b09e",
   "metadata": {},
   "source": [
    "# training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a72efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# val_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  \n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(f'{model_select}-Model validation loss')\n",
    "plt.ylim([1e-5, 10])  \n",
    "plt.yscale('log')  \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "  \n",
    "data = []  \n",
    "for i in range(len(history.history['val_loss'])):  \n",
    "    data.append([i, history.history['val_loss'][i]])  \n",
    "df = pd.DataFrame(data, columns=['Epoch', 'Loss'])  \n",
    "  \n",
    "    \n",
    "\n",
    "output_folder = folder_path\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "file_name=os.path.splitext(file_name)[0]\n",
    "file_name_pre = os.path.join(output_folder, f\"{file_name}-{model_select}-Model Loss curve.xlsx\")\n",
    "\n",
    "if os.path.exists(file_name_pre):\n",
    "    os.remove(file_name_pre)\n",
    "\n",
    "df.to_excel(file_name_pre, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6429f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred = np.squeeze(y_pred)\n",
    "\n",
    "\n",
    "R2 = r2_score(y_test,y_pred) \n",
    "MAPE = mean_absolute_percentage_error(y_test,y_pred)\n",
    "MSE = mean_squared_error(y_test,y_pred) \n",
    "\n",
    "data_metrics = { \n",
    "        'R2': R2,\n",
    "        'MAPE': MAPE,\n",
    "        'MSE': MSE,\n",
    "    }\n",
    "print (data_metrics)\n",
    "\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([0, 8], [0, 8], color='black', linestyle='-', linewidth=1)\n",
    "plt.title(f'{model_select}-Model Actual_strain vs Predicted_strain')\n",
    "plt.xlabel('Actual_strain(%)')\n",
    "plt.ylabel('Predicted_strain(%)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \n",
    "df2 = pd.DataFrame(data_metrics, index=[0])  \n",
    "\n",
    "\n",
    "file_name_pre = os.path.join(output_folder, f\"{file_name}-{model_select}-Actual_strain vs Predicted_strain.xlsx\")\n",
    "\n",
    "if os.path.exists(file_name_pre):\n",
    "    os.remove(file_name_pre)\n",
    "\n",
    "\n",
    "df1.to_excel(file_name_pre, index=False)\n",
    "\n",
    "\n",
    "file_name_pre = os.path.join(output_folder, f\"{file_name}-{model_select}-R2-MAPE-MSE.xlsx\")\n",
    "\n",
    "if os.path.exists(file_name_pre):\n",
    "    os.remove(file_name_pre)\n",
    "df2.to_excel(file_name_pre, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e97a33",
   "metadata": {},
   "source": [
    "## predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b12abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temperature_new=820 #℃\n",
    "stress_new=350 #MPa\n",
    "time_new =500 #h\n",
    "point_number=500\n",
    "X_new = np.c_[np.full(point_number, temperature_new), np.full(point_number, stress_new), np.linspace(0, time_new, point_number)]\n",
    "X_new_scale = scaler.transform(X_new)\n",
    "\n",
    "model = load_model(f'{model_select}-model.h5')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "y_new_predict = model.predict(X_new_scale)\n",
    "\n",
    "ax.plot(X_new[:, -1], y_new_predict, label= model_select, lw=0.5)#\n",
    "ax.set_title(f'{temperature_new}℃/{stress_new}MPa  time-strain curve')\n",
    "ax.set_ylim(0, 8)\n",
    "plt.xlabel('Time(h)')\n",
    "plt.ylabel('Strain(%)')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "502.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
